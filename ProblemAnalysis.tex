\section{Problem Analysis}

Together with the companies from the Industrial Reality Hub mentioned in the Introduction, Saxion wants to investigate how virtual reality
can be rendered in the cloud in a safe and efficient manner. This involves looking at state-of-
the art technology in the field of virtual reality, cloud computing, rendering and machine learning for one
complete CloudVR pipeline. There are four research objectives here:

\subsection{Architecture for a cloud VR system}
One of the questions to be answered is what the CloudVR architecture should look like
in terms of hardware and software. This not only concerns the servers, but also whether there are local ones
rendering is required (see the next point).

\subsection{Latency}
Current market players such as Google Stadia \parencite{stadia}, GeForce Now \parencite{geforcenow} and Xbox xCloud \parencite{xcloud} already offer cloud gaming services that stream games over the internet. Powerful servers are used for rendering games that are then streamed to users in real time. A bottleneck with this technology is the latency (delay). This is because user input is first sent to a server, which renders these new images, after which they are sent back to the users, all without disturbing them. The mentioned platforms all use network optimization. Low latency is very important for VR, where head movements should be converted to images in under 20 \acrfull{ms}, to prevent motion sickness \parencite{valvevrlatency}. The research for techniques for reducing latency is one of the spearheads of the CloudVR project. The following research directions are relevant here:

\paragraph{Network optimization}
As with the platforms described above, network optimization is one of the techniques
which needs to be investigated. The question is to what extent an optimized network
can reduce latency and how it relates to the quality of the network connection.
\paragraph{Two-step rendering}
One of the options to bypass latency is to render in two steps.
The delay is not so much reduced, but avoided. The server renders next to
\acrshort{rgb} also positions and BRDF variables for each pixel. Afterwards on the
user's (less powerful) hardware adjustments are made so that the image corresponds to the current position of the user.
By sending additional data, the user's local client can extrapolate the correct information and construct a frame that represents the correct head position in the last frame, meanwhile it is waiting for the  correct next frame from the server.
\paragraph{Behavioral prediction}
Another possibility to reduce latency is by predicting
user input through machine learning. This will mainly revolve around it
analyzing head movements to find out what behavior can be expected. With
this information we can render any part of the virtual world before it
is viewed by users. If this information is then forwarded from the
cloud to the location of the \acrshort{vr} experience, what information is displayed can be selected on the spot.

\subsection{Multi-user experiences}
One of the questions with a CloudVR solution is how to deal with multi-user \acrshort{vr} experience where
users at another location share a \acrshort{vr} experience via a network. The interaction with
each other and the environment are a point of attention.

\subsection{GPU scaling}
One of the advantages of cloud rendering is that in theory it gives the possibility of unlimited
computing capacity. This gives the opportunity to all kinds of touristic feats
(graphic), and interaction (physics). It is therefore interesting as part of the CloudVR pipeline
to investigate how techniques such as NVLink and NVSwitch 5 \parencite{nvlink} could be used for
high-quality \acrshort{vr} experiences.
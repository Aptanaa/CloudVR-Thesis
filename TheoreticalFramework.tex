\section{Theoretical Framework}
In order to thoroughly understand the aim and subject of the report, it is important to explore different existing solutions and literature. Therefore, the subjects that will be discussed in the following theoretical framework are Cloud Streaming/Cloud Computing, Virtual Reality and Security in a streaming context. Within this theoretical framework definitions of the subjects will be given, as well as current insights into these subjects. The topics reflect knowledge needed to understand the problem space. Together all of the topics make up the 360 scan. Then this knowledge will be applied to the research problem by creating an overview of the individual parts of a cloud \acrshort{vr} system and of the available components to create one.  Lastly I will be proposing technology stacks, made up of said components, that can satisfy all necessary aspects of a cloud \acrshort{vr} system as described in the overview.

\subsection{Cloud Streaming/Cloud Computing}

\subsubsection{Definition}
According to Armbrust et al. (2010) Cloud computing is defined as follows: 
"Cloud computing refers to both the applications delivered as services over the Internet and the hardware and systems software in the data centres that provide those services." \parencite{aviewoncc}
We can then further define Cloud streaming as the applications that are delivered over the internet as a service.

\subsubsection{Existing Solutions and Technology}
Several commercial gaming cloud streaming services already exist, such as Google Stadia \parencite{stadia}, XBox XCloud \parencite{xcloud} and Nvidia GeForceNow \parencite{geforcenow}. These applications deliver conventional games from a powerful computer in a server to the client device at home. Despite initial setbacks, cloud streaming is now a mainstream technology. The start of 2020 also saw the first experimental cloud \acrshort{vr} streaming development kits, such as Nvidia's CloudXR \parencite{cloudxr}, and closed beta's for commercial cloud \acrshort{vr} streaming services \parencite{shadowvr}. Additionally the first commercial retail products with cloud \acrshort{vr} have been released \parencite{zerolight5g}. There is also a variety of Infrastructure\hyp{}as\hyp{}a\hyp{}service (IaaS) platforms, such as Amazon's AWS \parencite{aws}, Microsoft's Azure \parencite{azure} and Google's Cloud Platform \parencite{gcp}, that provide generic computing power and storage in a cloud computing/streaming context. These services generally cannot achieve the \hyperref[ssec:vrphy]{latency requirements} of cloud \acrshort{vr} streaming \parencite{survey_IRSS}, but companies are actively working on finding a solution \parencite{awswavelength}. For more information about these applications and technologies, please refer to the \hyperref[sec:lit]{Literature Analysis}.

\subsubsection{System Architecture types (for a cloud VR system)}
\begin{figure}[h]
\caption{Cloud Server, Remote Edge, Local Edge visualized \parencite{wlanvr}}
\label{fig:arch1}
\includegraphics[scale=0.45]{Architectures1}
\end{figure}

One of the main considerations when designing a cloud \acrshort{vr} streaming application is the decision to either use a Cloud, Remote Edge or Local Edge computing device for the rendering of the frames (See \hyperref[fig:arch1]{Figure 1} and \cite{wlanvr}):
\begin{itemize}
\item A cloud server renders the \acrfull{fov} (current view) remotely and streams the corresponding video to the user’s \acrfull{hmd}. 
\item A Remote Edge sever receives multiple views that are rendered remotely on cloud servers, stitches them together to a 360-degree video, and streams the video to the user’s \acrshort{hmd}
\item A Local Edge server receives compressed models as well as textures, renders it locally and streams the video to the user’s \acrshort{hmd}.
\end{itemize} 

\begin{figure}[!htbp]
\caption{Example System Architecture}
\label{fig:sysarch}
\includegraphics[scale=0.45]{SimpleArchitecture}
\end{figure}

For the purposes of this research I will ignore Local Edge system architectures. The reason is that one of the major motivations for this report was the desire to keep data as safe as possible, which in this case means keeping in the cloud. A Local Edge system by design requests and receives business data to render the frame for the user locally. For this reason a Local Edge approach would be the wrong direction to research in. An example architecture of a cloud \acrshort{vr} solution that keeps the business data in the cloud can be seen in \hyperref[fig:sysarch]{Figure 2}.

Furthermore one also has to consider if the application will be hosted on a cloud service provider or on an in-house server. Both ways have advantages and disadvantages, which are elaborated upon in \hyperref[app:swot]{the Appendices}, and the decision should be made based on the unique circumstances of each customer.

\subsubsection{Latency}
The most important metric for a system architecture is the latency between the user input, such as movement of the \acrshort{hmd}, and the updated frame appearing on the users display. Recent measurements of cloud gaming services measure this latency at between 135 and 240\acrshort{ms} \parencite{lagmeasure}. This is acceptable for most games, except maybe high intensity reaction games. \acrshort{vr} unfortunately has severely stricter latency requirements, which are elaborated upon in \hyperref[ssec:vrphy]{the next section}.

\subsection{Constraints of Virtual Reality}
\label{ssec:vrphy}
As mentioned before, when developing a \acrshort{vr} application, there are a few physical constraints that developers need to be aware of. The most important threshold to know is the 20\acrshort{ms} \acrshort{mtp} delay. Upon input from the \acrshort{hmd}, the developer has to display a new rendered image within an average of 20\acrshort{ms} to avoid motion sickness for users. The more this threshold can be undercut, the better the chances to have an acceptable gameplay experience without motion sickness. Interaction input, such as the input from the controllers, can safely be processed at delays of $>$100\acrshort{ms} without any negative repercussions in terms of \acrfull{qoe}. For more information, please refer to the \hyperref[sec:lit]{Literature Analysis}.

\subsection{Security (for streaming data)}
From a technical standpoint there are 2 major categories of security implementations: Encryption and Access management. There are additional measures that companies can take such as having consistent security protocols and educating employees, but for this report the focus is on technical solutions:

\subsubsection{Encryption}
Encryption is the practice of scrambling data so that unauthorized users cannot use the data. Only an authorized party in possession of the decryption key can un-scramble the data and subsequently use it. 
One such encryption technologies is the \acrfull{aes}, which comes with three different key sizes: 128, 192 and 256 bits. In 2016 it was estimated that it would take 500,000,000,000 years to decrypt just one \acrshort{aes}-128 key.
To encrypt the data in delivery, a technology such as the \acrfull{tls} can be used, which encrypts the data based on a shared secret that was negotiated at the start of the session, thus making the data only usable for the server and client who have the decryption key.
\subsubsection{\acrfull{iam}}
An \acrshort{iam} solution tracks users and what they are allowed to do. There are multiple existing solutions for tracking the users privileges, but for this report only cloud based services are relevant since the premise of this research is the ability to have a cloud solution. All major cloud providers have \acrshort{iam} solutions in their ecosystem and in case of a in-house server a independent \acrshort{iam} service provider can satisfy that requirement.

\subsubsection{Latency Implications}


\subsection{Components of a cloud \acrshort{vr} pipeline}
In this section all the individual components of a cloud \acrshort{vr} pipeline are being presented. Furthermore an overview of pre-made components will be presented and which part of the pipeline they address.

\begin{figure}[h!]
\caption{Overview of components in a typical cloud \acrshort{vr} pipeline}
\label{fig:pipeline}
\includegraphics[scale=0.4]{CloudVR_PipelineComponents}
\end{figure}

\paragraph{\textSR}
The actual \acrshort{vr} application will be running on the cloud server and use the servers hardware to render the game. The application will be running on the OpenVR SDK, which allows access to VR hardware from multiple vendors without requiring that applications have specific knowledge of the hardware they are targeting \parencite{openvrsdk}. 
\paragraph{\textSECO}
The rendered frames will be encoded with a video compression codec before they are sent to the networking layer.
\paragraph{\textSECR}
Before transmitting the data (encoded frames) over the network it will be encrypted to maximise security.
\paragraph{\textN}
Through the network connection both the output (rendered, encoded and encrypted frames) and the input (\acrshort{hmd} position and controller input) will be exchanged between the server and the client.
\paragraph{\textCDCR}
Once received from the networking layer, the frames are decrypted to prepare for decoding.
\paragraph{\textCDCO}
Once decrypted to usable packages, the data will be decoded and then sent to the VR Runtime
\paragraph{\textCRD}
The decoded frames will be warped to fit the lenses of the \acrshort{hmd} and then finally be displayed to the user.


\subsubsection{Available components}
\renewcommand{\arraystretch}{1.5}

\begin{longtable}{  | p{0.15\linewidth} | p{0.5\linewidth} | p{0.35\linewidth} | }
\caption{Available Components} \\
\hline
\textbf{Name} & \textbf{Description} & \textbf{Solves} \\ 
\hline
NVIDIA CloudXR SDK & NVIDIA CloudXR™, a groundbreaking technology built on NVIDIA RTX™, delivers VR and AR across 5G and Wi-Fi networks. With NVIDIA GPU virtualization software, CloudXR is fully scalable for data center and edge networks \parencite{cloudxr}. & \textSECO , \textSECR ,  \textN , \textCDCR , \textCDCO , \textCRD \\
\hline
Seurat & Seurat is a system for image-based scene simplification for VR. It converts complex 3D scenes with millions of triangles, including complex lighting and shading effects, into just tens of thousands of triangles that can be rendered very efficiently on 6DOF devices with little loss in visual quality \parencite{seurat}. & \textSR  \\
\hline
H.264 & H.264 is a video compression standard based on block-oriented, motion-compensated integer-DCT coding.[1] It is by far the most commonly used format for the recording, compression, and distribution of video content. It supports resolutions up to and including 8K UHD. & \textSECO , \textCDCO \\
\hline
VP8 & VP8 is an open and royalty free video compression format.  & \textSECO , \textCDCO \\
\hline
\acrfull{aes}  & \acrshort{aes} is a specification for the encryption of electronic data. & \textSECR , \textCDCR \\
\hline
\acrfull{tls} & \acrshort{tls} is a cryptographic protocol designed to provide communications security over a computer network by utilizing the \acrshort{aes} technology. & \textSECR , \textCDCR , \textN \\
\hline
WebRTC & With WebRTC, you can add real-time communication capabilities to your application that works on top of an open standard. It supports video, voice, and generic data to be sent between peers, allowing developers to build powerful voice- and video-communication solutions. The technology is available on all modern browsers as well as on native clients for all major platforms \parencite{webRTC}. & \textN \\
\hline
\end{longtable}

\newpage
\subsection{Proposed Technology Stacks}
Finally in this section different technology stacks will be presented, all of which meet the requirements as detailed in the previous section.
\subsubsection{NVIDIA CloudXR + NVIDIA Quadro on Azure}
The CloudXR SDK from NVIDIA offers a complete solution package to stream VR/AR experiences from server to client. As the only complete package in this list it is a good starting point to create a cloud \acrshort{vr} streaming prototype. Since Azure is the chosen cloud provider of Thales, one of the major stakeholders, the idea would be to deploy this tech stack there. \\
\newline
\begin{varwidth}[t]{.5\textwidth}
\renewcommand\labelitemi{+}
\textbf{Pros:}
\begin{itemize}
\item Only complete solution
\item Rapid prototyping speed (presumably)
\item Custom made for streaming \acrshort{vr} content
\item Created by one of the leading companies in the field of (remote) rendering
\end{itemize}
\end{varwidth}
\hspace{4em}
\begin{varwidth}[t]{.5\textwidth}
\renewcommand\labelitemi{-}
\textbf{Cons:}
\begin{itemize}
\item Forced to use NVIDIA products
\item Not guaranteed to get access to solution (Have to apply to NVIDIA)
\item Limited control about the solution
\item Limited documentation about the solution, since it is brand new
\end{itemize}
\end{varwidth}

\subsubsection{WebRTC + High Performance Video Codec}
WebRTC is one of the premier web technologies to enable real time communications. Since it allows for streaming video and generic data it is a good candidate to create a cloud \acrshort{vr} streaming prototype, because it can transfer both the video and input data. As it has a focus on real time communication it is optimized to reduce latency by default, however it is unclear if this is enough optimization by itself to support streaming \acrshort{vr} content. \\
\newline
\begin{varwidth}[t]{.5\textwidth}
\renewcommand\labelitemi{+}
\textbf{Pros:}
\begin{itemize}
\item Open source
\item Mature technology
\item Well documented and supported
\item Platform independent
\item Developed by the same companies that offer cloud computing services (improved integration ?)
\end{itemize}
\end{varwidth}
\hspace{4em}
\begin{varwidth}[t]{.5\textwidth}
\renewcommand\labelitemi{-}
\textbf{Cons:}
\begin{itemize}
\item Generalized solution (it will  take more work to optimize it for \acrshort{vr})
\item Lower performance Web Technology (but there are native clients for all major platforms available)
\item Higher complexity (might run out of time while trying to create the prototype)
\end{itemize}
\end{varwidth}